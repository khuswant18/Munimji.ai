"""add_cascade_delete_for_user_relations

Revision ID: 8660615f8547
Revises: 627a99c96391
Create Date: 2025-11-26 02:33:27.777133

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '8660615f8547'
down_revision: Union[str, Sequence[str], None] = '627a99c96391'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.execute("DROP TABLE IF EXISTS langchain_pg_collection CASCADE")
    op.drop_index(op.f('ix_cmetadata_gin'), table_name='langchain_pg_embedding', postgresql_ops={'cmetadata': 'jsonb_path_ops'}, postgresql_using='gin')
    op.execute("DROP TABLE IF EXISTS langchain_pg_embedding CASCADE")
    op.drop_constraint(op.f('conversations_user_id_fkey'), 'conversations', type_='foreignkey')
    op.create_foreign_key(None, 'conversations', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    op.drop_constraint(op.f('customers_user_id_fkey'), 'customers', type_='foreignkey')
    op.create_foreign_key(None, 'customers', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    op.drop_constraint(op.f('ledger_entries_user_id_fkey'), 'ledger_entries', type_='foreignkey')
    op.create_foreign_key(None, 'ledger_entries', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    op.drop_constraint(op.f('memory_user_id_fkey'), 'memory', type_='foreignkey')
    op.create_foreign_key(None, 'memory', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    op.drop_constraint(op.f('suppliers_user_id_fkey'), 'suppliers', type_='foreignkey')
    op.create_foreign_key(None, 'suppliers', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'suppliers', type_='foreignkey')
    op.create_foreign_key(op.f('suppliers_user_id_fkey'), 'suppliers', 'users', ['user_id'], ['id'])
    op.drop_constraint(None, 'memory', type_='foreignkey')
    op.create_foreign_key(op.f('memory_user_id_fkey'), 'memory', 'users', ['user_id'], ['id'])
    op.drop_constraint(None, 'ledger_entries', type_='foreignkey')
    op.create_foreign_key(op.f('ledger_entries_user_id_fkey'), 'ledger_entries', 'users', ['user_id'], ['id'])
    op.drop_constraint(None, 'customers', type_='foreignkey')
    op.create_foreign_key(op.f('customers_user_id_fkey'), 'customers', 'users', ['user_id'], ['id'])
    op.drop_constraint(None, 'conversations', type_='foreignkey')
    op.create_foreign_key(op.f('conversations_user_id_fkey'), 'conversations', 'users', ['user_id'], ['id'])
    op.create_table('langchain_pg_embedding',
    sa.Column('id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('collection_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('embedding', pgvector.sqlalchemy.vector.VECTOR(), autoincrement=False, nullable=True),
    sa.Column('document', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('cmetadata', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['collection_id'], ['langchain_pg_collection.uuid'], name=op.f('langchain_pg_embedding_collection_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('langchain_pg_embedding_pkey'))
    )
    op.create_index(op.f('ix_cmetadata_gin'), 'langchain_pg_embedding', ['cmetadata'], unique=False, postgresql_ops={'cmetadata': 'jsonb_path_ops'}, postgresql_using='gin')
    op.create_table('langchain_pg_collection',
    sa.Column('uuid', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('cmetadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('uuid', name=op.f('langchain_pg_collection_pkey')),
    sa.UniqueConstraint('name', name=op.f('langchain_pg_collection_name_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    # ### end Alembic commands ###
